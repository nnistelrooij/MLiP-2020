{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM \n",
    "\n",
    "Kaggle kernel:\n",
    "https://www.kaggle.com/ar2017/m5-forecasting-lightgbm#Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from  datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_dir = './kaggle/input/m5-forecasting-accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>d</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>11101</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>11101</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  wm_yr_wk  weekday  wday  month  year    d  event_name_1  \\\n",
       "0 2011-01-29     11101        2     1      1  2011  d_1             0   \n",
       "1 2011-01-30     11101        3     2      1  2011  d_2             0   \n",
       "2 2011-01-31     11101        1     3      1  2011  d_3             0   \n",
       "3 2011-02-01     11101        5     4      2  2011  d_4             0   \n",
       "4 2011-02-02     11101        6     5      2  2011  d_5             0   \n",
       "\n",
       "   event_type_1  event_name_2  event_type_2  snap_CA  snap_TX  snap_WI  \n",
       "0             0             0             0        0        0        0  \n",
       "1             0             0             0        0        0        0  \n",
       "2             0             0             0        0        0        0  \n",
       "3             0             0             0        1        1        0  \n",
       "4             0             0             0        1        0        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correct data types for \"calendar.csv\"\n",
    "calendarDTypes = {\"event_name_1\": \"category\", \n",
    "                  \"event_name_2\": \"category\", \n",
    "                  \"event_type_1\": \"category\", \n",
    "                  \"event_type_2\": \"category\", \n",
    "                  \"weekday\": \"category\", \n",
    "                  \"wm_yr_wk\": \"int16\", \n",
    "                  \"wday\": \"int16\",\n",
    "                  \"month\": \"int16\", \n",
    "                  \"year\": \"int16\", \n",
    "                  \"snap_CA\": \"int16\", \n",
    "                  \"snap_TX\": \"int16\", \n",
    "                  \"snap_WI\": \"int16\" }\n",
    "\n",
    "# Read csv file\n",
    "calendar = pd.read_csv(f\"{data_dir}/calendar.csv\", \n",
    "                       dtype = calendarDTypes)\n",
    "calendar[\"date\"] = pd.to_datetime(calendar[\"date\"])\n",
    "\n",
    "# Transform categorical features into integers\n",
    "for col, colDType in calendarDTypes.items():\n",
    "    if colDType == \"category\":\n",
    "        calendar[col] = calendar[col].cat.codes.astype(\"int16\")\n",
    "        calendar[col] -= calendar[col].min()\n",
    "\n",
    "calendar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11325</td>\n",
       "      <td>9.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11326</td>\n",
       "      <td>9.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11327</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11328</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11329</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store_id  item_id  wm_yr_wk  sell_price\n",
       "0         0        0     11325        9.58\n",
       "1         0        0     11326        9.58\n",
       "2         0        0     11327        8.26\n",
       "3         0        0     11328        8.26\n",
       "4         0        0     11329        8.26"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correct data types for \"sell_prices.csv\"\n",
    "priceDTypes = {\"store_id\": \"category\", \n",
    "               \"item_id\": \"category\", \n",
    "               \"wm_yr_wk\": \"int16\",\n",
    "               \"sell_price\":\"float32\"}\n",
    "\n",
    "# Read csv file\n",
    "prices = pd.read_csv(f\"{data_dir}/sell_prices.csv\", \n",
    "                     dtype = priceDTypes)\n",
    "\n",
    "# Transform categorical features into integers\n",
    "for col, colDType in priceDTypes.items():\n",
    "    if colDType == \"category\":\n",
    "        prices[col] = prices[col].cat.codes.astype(\"int16\")\n",
    "        prices[col] -= prices[col].min()\n",
    "        \n",
    "prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>...</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1548</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2015-04-25</td>\n",
       "      <td>11513</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-04-26</td>\n",
       "      <td>11513</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-04-27</td>\n",
       "      <td>11513</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-04-28</td>\n",
       "      <td>11513</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-04-29</td>\n",
       "      <td>11513</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id  item_id  dept_id  store_id  cat_id  \\\n",
       "0  HOBBIES_1_001_CA_1_validation        0        0         0       0   \n",
       "1  HOBBIES_1_001_CA_1_validation        0        0         0       0   \n",
       "2  HOBBIES_1_001_CA_1_validation        0        0         0       0   \n",
       "3  HOBBIES_1_001_CA_1_validation        0        0         0       0   \n",
       "4  HOBBIES_1_001_CA_1_validation        0        0         0       0   \n",
       "\n",
       "   state_id       d  sales       date  wm_yr_wk  ...  month  year  \\\n",
       "0         0  d_1548    2.0 2015-04-25     11513  ...      4  2015   \n",
       "1         0  d_1549    0.0 2015-04-26     11513  ...      4  2015   \n",
       "2         0  d_1550    1.0 2015-04-27     11513  ...      4  2015   \n",
       "3         0  d_1551    0.0 2015-04-28     11513  ...      4  2015   \n",
       "4         0  d_1552    0.0 2015-04-29     11513  ...      4  2015   \n",
       "\n",
       "   event_name_1  event_type_1  event_name_2  event_type_2  snap_CA  snap_TX  \\\n",
       "0             0             0             0             0        0        0   \n",
       "1             0             0             0             0        0        0   \n",
       "2             0             0             0             0        0        0   \n",
       "3             0             0             0             0        0        0   \n",
       "4             0             0             0             0        0        0   \n",
       "\n",
       "   snap_WI  sell_price  \n",
       "0        0        8.26  \n",
       "1        0        8.26  \n",
       "2        0        8.26  \n",
       "3        0        8.26  \n",
       "4        0        8.26  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# firstDay = 250\n",
    "firstDay = 1913 - 365\n",
    "lastDay = 1913\n",
    "\n",
    "# Use x sales days (columns) for training\n",
    "numCols = [f\"d_{day}\" for day in range(firstDay, lastDay+1)]\n",
    "\n",
    "# Define all categorical columns\n",
    "catCols = ['id', 'item_id', 'dept_id','store_id', 'cat_id', 'state_id']\n",
    "\n",
    "# Define the correct data types for \"sales_train_validation.csv\"\n",
    "dtype = {numCol: \"float32\" for numCol in numCols} \n",
    "dtype.update({catCol: \"category\" for catCol in catCols if catCol != \"id\"})\n",
    "\n",
    "# Read csv file\n",
    "ds = pd.read_csv(f\"{data_dir}/sales_train_validation.csv\", \n",
    "                 usecols = catCols + numCols, dtype = dtype)\n",
    "\n",
    "# Transform categorical features into integers\n",
    "for col in catCols:\n",
    "    if col != \"id\":\n",
    "        ds[col] = ds[col].cat.codes.astype(\"int16\")\n",
    "        ds[col] -= ds[col].min()\n",
    "        \n",
    "ds = pd.melt(ds,\n",
    "             id_vars = catCols,\n",
    "             value_vars = [col for col in ds.columns if col.startswith(\"d_\")],\n",
    "             var_name = \"d\",\n",
    "             value_name = \"sales\")\n",
    "\n",
    "# Merge \"ds\" with \"calendar\" and \"prices\" dataframe\n",
    "ds = ds.merge(calendar, on = \"d\", copy = False)\n",
    "ds = ds.merge(prices, on = [\"store_id\", \"item_id\", \"wm_yr_wk\"], copy = False)\n",
    "\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dayLags = [7, 28]\n",
    "lagSalesCols = [f\"lag_{dayLag}\" for dayLag in dayLags]\n",
    "for dayLag, lagSalesCol in zip(dayLags, lagSalesCols):\n",
    "    ds[lagSalesCol] = ds[[\"id\",\"sales\"]].groupby(\"id\")[\"sales\"].shift(dayLag)\n",
    "    \n",
    "windows = [7, 28]\n",
    "for window in windows:\n",
    "    for dayLag, lagSalesCol in zip(dayLags, lagSalesCols):\n",
    "        ds[f\"rmean_{dayLag}_{window}\"] = ds[[\"id\", lagSalesCol]] \\\n",
    "                                            .groupby(\"id\")[lagSalesCol] \\\n",
    "                                            .transform(lambda x: x.rolling(window).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateFeatures = {\"wday\": \"weekday\",\n",
    "                \"week\": \"weekofyear\",\n",
    "                \"month\": \"month\",\n",
    "                \"quarter\": \"quarter\",\n",
    "                \"year\": \"year\",\n",
    "                \"mday\": \"day\"}\n",
    "\n",
    "for featName, featFunc in dateFeatures.items():\n",
    "    if featName in ds.columns:\n",
    "        ds[featName] = ds[featName].astype(\"int16\")\n",
    "    else:\n",
    "        ds[featName] = getattr(ds[\"date\"].dt, featFunc).astype(\"int16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11126888 entries, 0 to 11126887\n",
      "Data columns (total 31 columns):\n",
      " #   Column        Dtype         \n",
      "---  ------        -----         \n",
      " 0   id            object        \n",
      " 1   item_id       int16         \n",
      " 2   dept_id       int16         \n",
      " 3   store_id      int16         \n",
      " 4   cat_id        int16         \n",
      " 5   state_id      int16         \n",
      " 6   d             object        \n",
      " 7   sales         float32       \n",
      " 8   date          datetime64[ns]\n",
      " 9   wm_yr_wk      int16         \n",
      " 10  weekday       int16         \n",
      " 11  wday          int16         \n",
      " 12  month         int16         \n",
      " 13  year          int16         \n",
      " 14  event_name_1  int16         \n",
      " 15  event_type_1  int16         \n",
      " 16  event_name_2  int16         \n",
      " 17  event_type_2  int16         \n",
      " 18  snap_CA       int16         \n",
      " 19  snap_TX       int16         \n",
      " 20  snap_WI       int16         \n",
      " 21  sell_price    float32       \n",
      " 22  lag_7         float32       \n",
      " 23  lag_28        float32       \n",
      " 24  rmean_7_7     float32       \n",
      " 25  rmean_28_7    float32       \n",
      " 26  rmean_7_28    float32       \n",
      " 27  rmean_28_28   float32       \n",
      " 28  week          int16         \n",
      " 29  quarter       int16         \n",
      " 30  mday          int16         \n",
      "dtypes: datetime64[ns](1), float32(8), int16(20), object(2)\n",
      "memory usage: 1.1+ GB\n"
     ]
    }
   ],
   "source": [
    "ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all rows with NaN value\n",
    "ds.dropna(inplace = True)\n",
    "\n",
    "# Define columns that need to be removed\n",
    "unusedCols = [\"id\", \"date\", \"sales\",\"d\", \"wm_yr_wk\", \"weekday\"]\n",
    "trainCols = ds.columns[~ds.columns.isin(unusedCols)]\n",
    "X_train = ds[trainCols]\n",
    "y_train = ds[\"sales\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(777)\n",
    "\n",
    "# Define categorical features\n",
    "catFeats = ['item_id', 'dept_id','store_id', 'cat_id', 'state_id'] + \\\n",
    "           [\"event_name_1\", \"event_name_2\", \"event_type_1\", \"event_type_2\"]\n",
    "\n",
    "# 2_000_000 in Kaggle kernel but results in memory error\n",
    "validInds = np.random.choice(X_train.index.values, 1_000_000, replace = False)\n",
    "trainInds = np.setdiff1d(X_train.index.values, validInds)\n",
    "\n",
    "trainData = lgb.Dataset(X_train.loc[trainInds], label = y_train.loc[trainInds], \n",
    "                        categorical_feature = catFeats, free_raw_data = False)\n",
    "validData = lgb.Dataset(X_train.loc[validInds], label = y_train.loc[validInds],\n",
    "                        categorical_feature = catFeats, free_raw_data = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del ds, X_train, y_train, validInds, trainInds ; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "          \"objective\" : \"poisson\",\n",
    "          \"metric\" :\"rmse\",\n",
    "          \"force_row_wise\" : True,\n",
    "          \"learning_rate\" : 0.075,\n",
    "          \"sub_row\" : 0.75,\n",
    "          \"bagging_freq\" : 1,\n",
    "          \"lambda_l2\" : 0.1,\n",
    "          \"metric\": [\"rmse\"],\n",
    "          'verbosity': 1,\n",
    "          'num_iterations' : 200,\n",
    "          'num_leaves': 128,\n",
    "          \"min_data_in_leaf\": 100,\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda2\\envs\\py37_M5\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "D:\\Anaconda2\\envs\\py37_M5\\lib\\site-packages\\lightgbm\\basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\tvalid_0's rmse: 2.50049\n",
      "[40]\tvalid_0's rmse: 2.21545\n",
      "[60]\tvalid_0's rmse: 2.14316\n",
      "[80]\tvalid_0's rmse: 2.12163\n",
      "[100]\tvalid_0's rmse: 2.1125\n",
      "[120]\tvalid_0's rmse: 2.10602\n",
      "[140]\tvalid_0's rmse: 2.0989\n",
      "[160]\tvalid_0's rmse: 2.09289\n",
      "[180]\tvalid_0's rmse: 2.08744\n",
      "[200]\tvalid_0's rmse: 2.08301\n"
     ]
    }
   ],
   "source": [
    "m_lgb = lgb.train(params, trainData, valid_sets = [validData], verbose_eval = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x1943cb16550>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_lgb.save_model(\"model_365d_200it.lgb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last day used for training\n",
    "trLast = 1913\n",
    "# Maximum lag day\n",
    "maxLags = 57\n",
    "\n",
    "# Create dataset for predictions\n",
    "def create_ds():\n",
    "    \n",
    "    startDay = trLast - maxLags\n",
    "    \n",
    "    numCols = [f\"d_{day}\" for day in range(startDay, trLast + 1)]\n",
    "    catCols = ['id', 'item_id', 'dept_id','store_id', 'cat_id', 'state_id']\n",
    "    \n",
    "    dtype = {numCol:\"float32\" for numCol in numCols} \n",
    "    dtype.update({catCol: \"category\" for catCol in catCols if catCol != \"id\"})\n",
    "    \n",
    "    ds = pd.read_csv(f\"{data_dir}/sales_train_validation.csv\", \n",
    "                     usecols = catCols + numCols, dtype = dtype)\n",
    "    \n",
    "    for col in catCols:\n",
    "        if col != \"id\":\n",
    "            ds[col] = ds[col].cat.codes.astype(\"int16\")\n",
    "            ds[col] -= ds[col].min()\n",
    "    \n",
    "    for day in range(trLast + 1, trLast+ 28 +1):\n",
    "        ds[f\"d_{day}\"] = np.nan\n",
    "    \n",
    "    ds = pd.melt(ds,\n",
    "                 id_vars = catCols,\n",
    "                 value_vars = [col for col in ds.columns if col.startswith(\"d_\")],\n",
    "                 var_name = \"d\",\n",
    "                 value_name = \"sales\")\n",
    "    \n",
    "    ds = ds.merge(calendar, on = \"d\", copy = False)\n",
    "    ds = ds.merge(prices, on = [\"store_id\", \"item_id\", \"wm_yr_wk\"], copy = False)\n",
    "    \n",
    "    return ds\n",
    "\n",
    "def create_features(ds):          \n",
    "    dayLags = [7, 28]\n",
    "    lagSalesCols = [f\"lag_{dayLag}\" for dayLag in dayLags]\n",
    "    for dayLag, lagSalesCol in zip(dayLags, lagSalesCols):\n",
    "        ds[lagSalesCol] = ds[[\"id\",\"sales\"]].groupby(\"id\")[\"sales\"].shift(dayLag)\n",
    "\n",
    "    windows = [7, 28]\n",
    "    for window in windows:\n",
    "        for dayLag, lagSalesCol in zip(dayLags, lagSalesCols):\n",
    "            ds[f\"rmean_{dayLag}_{window}\"] = ds[[\"id\", lagSalesCol]].groupby(\"id\")[lagSalesCol].transform(lambda x: x.rolling(window).mean())\n",
    "          \n",
    "    dateFeatures = {\"wday\": \"weekday\",\n",
    "                    \"week\": \"weekofyear\",\n",
    "                    \"month\": \"month\",\n",
    "                    \"quarter\": \"quarter\",\n",
    "                    \"year\": \"year\",\n",
    "                    \"mday\": \"day\"}\n",
    "\n",
    "    for featName, featFunc in dateFeatures.items():\n",
    "        if featName in ds.columns:\n",
    "            ds[featName] = ds[featName].astype(\"int16\")\n",
    "        else:\n",
    "            ds[featName] = getattr(ds[\"date\"].dt, featFunc).astype(\"int16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2016-04-25 00:00:00\n",
      "1 2016-04-26 00:00:00\n",
      "2 2016-04-27 00:00:00\n",
      "3 2016-04-28 00:00:00\n",
      "4 2016-04-29 00:00:00\n",
      "5 2016-04-30 00:00:00\n",
      "6 2016-05-01 00:00:00\n",
      "7 2016-05-02 00:00:00\n",
      "8 2016-05-03 00:00:00\n",
      "9 2016-05-04 00:00:00\n",
      "10 2016-05-05 00:00:00\n",
      "11 2016-05-06 00:00:00\n",
      "12 2016-05-07 00:00:00\n",
      "13 2016-05-08 00:00:00\n",
      "14 2016-05-09 00:00:00\n",
      "15 2016-05-10 00:00:00\n",
      "16 2016-05-11 00:00:00\n",
      "17 2016-05-12 00:00:00\n",
      "18 2016-05-13 00:00:00\n",
      "19 2016-05-14 00:00:00\n",
      "20 2016-05-15 00:00:00\n",
      "21 2016-05-16 00:00:00\n",
      "22 2016-05-17 00:00:00\n",
      "23 2016-05-18 00:00:00\n",
      "24 2016-05-19 00:00:00\n",
      "25 2016-05-20 00:00:00\n",
      "26 2016-05-21 00:00:00\n",
      "27 2016-05-22 00:00:00\n",
      "0 1.028 0.3333333333333333\n",
      "0 2016-04-25 00:00:00\n",
      "1 2016-04-26 00:00:00\n",
      "2 2016-04-27 00:00:00\n",
      "3 2016-04-28 00:00:00\n",
      "4 2016-04-29 00:00:00\n",
      "5 2016-04-30 00:00:00\n",
      "6 2016-05-01 00:00:00\n",
      "7 2016-05-02 00:00:00\n",
      "8 2016-05-03 00:00:00\n",
      "9 2016-05-04 00:00:00\n",
      "10 2016-05-05 00:00:00\n",
      "11 2016-05-06 00:00:00\n",
      "12 2016-05-07 00:00:00\n",
      "13 2016-05-08 00:00:00\n",
      "14 2016-05-09 00:00:00\n",
      "15 2016-05-10 00:00:00\n",
      "16 2016-05-11 00:00:00\n",
      "17 2016-05-12 00:00:00\n",
      "18 2016-05-13 00:00:00\n",
      "19 2016-05-14 00:00:00\n",
      "20 2016-05-15 00:00:00\n",
      "21 2016-05-16 00:00:00\n",
      "22 2016-05-17 00:00:00\n",
      "23 2016-05-18 00:00:00\n",
      "24 2016-05-19 00:00:00\n",
      "25 2016-05-20 00:00:00\n",
      "26 2016-05-21 00:00:00\n",
      "27 2016-05-22 00:00:00\n",
      "1 1.023 0.3333333333333333\n",
      "0 2016-04-25 00:00:00\n",
      "1 2016-04-26 00:00:00\n",
      "2 2016-04-27 00:00:00\n",
      "3 2016-04-28 00:00:00\n",
      "4 2016-04-29 00:00:00\n",
      "5 2016-04-30 00:00:00\n",
      "6 2016-05-01 00:00:00\n",
      "7 2016-05-02 00:00:00\n",
      "8 2016-05-03 00:00:00\n",
      "9 2016-05-04 00:00:00\n",
      "10 2016-05-05 00:00:00\n",
      "11 2016-05-06 00:00:00\n",
      "12 2016-05-07 00:00:00\n",
      "13 2016-05-08 00:00:00\n",
      "14 2016-05-09 00:00:00\n",
      "15 2016-05-10 00:00:00\n",
      "16 2016-05-11 00:00:00\n",
      "17 2016-05-12 00:00:00\n",
      "18 2016-05-13 00:00:00\n",
      "19 2016-05-14 00:00:00\n",
      "20 2016-05-15 00:00:00\n",
      "21 2016-05-16 00:00:00\n",
      "22 2016-05-17 00:00:00\n",
      "23 2016-05-18 00:00:00\n",
      "24 2016-05-19 00:00:00\n",
      "25 2016-05-20 00:00:00\n",
      "26 2016-05-21 00:00:00\n",
      "27 2016-05-22 00:00:00\n",
      "2 1.018 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "fday = datetime(2016,4, 25) \n",
    "alphas = [1.028, 1.023, 1.018]\n",
    "weights = [1/len(alphas)] * len(alphas)\n",
    "sub = 0.\n",
    "\n",
    "for icount, (alpha, weight) in enumerate(zip(alphas, weights)):\n",
    "\n",
    "    te = create_ds()\n",
    "    cols = [f\"F{i}\" for i in range(1,29)]\n",
    "\n",
    "    for tdelta in range(0, 28):\n",
    "        day = fday + timedelta(days=tdelta)\n",
    "        print(tdelta, day)\n",
    "        tst = te[(te['date'] >= day - timedelta(days=maxLags)) & (te['date'] <= day)].copy()\n",
    "        create_features(tst)\n",
    "        tst = tst.loc[tst['date'] == day , trainCols]\n",
    "        te.loc[te['date'] == day, \"sales\"] = alpha * m_lgb.predict(tst) # magic multiplier by kyakovlev\n",
    "\n",
    "    te_sub = te.loc[te['date'] >= fday, [\"id\", \"sales\"]].copy()\n",
    "    te_sub[\"F\"] = [f\"F{rank}\" for rank in te_sub.groupby(\"id\")[\"id\"].cumcount()+1]\n",
    "    te_sub = te_sub.set_index([\"id\", \"F\" ]).unstack()[\"sales\"][cols].reset_index()\n",
    "    te_sub.fillna(0., inplace = True)\n",
    "    te_sub.sort_values(\"id\", inplace = True)\n",
    "    te_sub.reset_index(drop=True, inplace = True)\n",
    "    te_sub.to_csv(f\"submission_{icount}.csv\",index=False)\n",
    "    if icount == 0 :\n",
    "        sub = te_sub\n",
    "        sub[cols] *= weight\n",
    "    else:\n",
    "        sub[cols] += te_sub[cols]*weight\n",
    "    print(icount, alpha, weight)\n",
    "\n",
    "\n",
    "sub2 = sub.copy()\n",
    "sub2[\"id\"] = sub2[\"id\"].str.replace(\"validation$\", \"evaluation\")\n",
    "sub = pd.concat([sub, sub2], axis=0, sort=False)\n",
    "sub.to_csv(\"submission.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
